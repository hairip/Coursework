{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc1c31",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"ps10.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5450b",
   "metadata": {},
   "source": [
    "# PS10: Using RDD and DataFrame in PySpark\n",
    "\n",
    "In this problemset you will hone your skills working with both RDD and spark Dataframe. This problemset has no hidden tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4459687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import collections\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate();\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dffa872",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "This problem concerns working with RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217e31b-f9b5-482a-92d6-4b819ed8dc7d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Q1a (3 points)\n",
    "\n",
    "This problemset has a text file named 'mother_theresa.txt'. An RDD of the textfile is created for you. Your job is to count how many words have 'mother' in it. 'mother' could be the whole string or part of the string. It still get counted as long as the entire 'mother' appears in the string. You also have to count the other words under the key 'other'. \n",
    "\n",
    "Hint: You would be using a mix of `flatMap`, `map` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1a3916-20a5-4c66-9956-46a6bc55d8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "rdd = sc.textFile('mother_theresa.txt')\n",
    "result1 = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ce375",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0bed6-bf74-46c9-8844-09cc4cb27ec0",
   "metadata": {},
   "source": [
    "### Q1b (2 points)\n",
    "\n",
    "Using the same RDD, find the length of each line in the text file first and then add the length of all the lines and display the total length of all lines. You need to strip the line before finding the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de71d99-1297-4d27-b4f4-047b282cd0bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "total_length = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010c8fd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a15f7-1a4d-4bf5-a43f-bc7defe6d211",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "This problem concerns working with PySpark Dataframe. We will revisit the cdc dataset from the last assignment. But this time we are using spark to do our analytics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d8bba-06ed-4eb9-9221-9b439da6d698",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Q2a (3 points)\n",
    "\n",
    "We will reuse the same query we built in the last problemset. Fortunitely spark dataframe works for the same pandas syntax!  Your job is to use this subquery and find the max datavalue for each unique locationabbr value. Display the first 10 datavalues in descending order\n",
    "\n",
    "Hint: One way to do that is to group by `locationabbr` and find the max datavalue with in the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11c530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = spark.read.csv('us_chronic_disease_indicators.csv', header = True)\n",
    "\n",
    "# you can use this expression to get a subset of data\n",
    "df[(~df['locationabbr'].isin(['US','PR', 'GU'])) &\n",
    "                (df['question'] == 'Alcohol use among youth')  &\n",
    "                (df['stratificationcategoryid1'] == 'OVERALL')]\n",
    "\n",
    "first_10_counts = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9cccc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539aa1f1-58c7-43c1-8cd4-f75a8dbdc80f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Q2b (3 points)\n",
    "\n",
    "We can save the dataframe into a temporary table and use spark SQL to run queries on the dataset.  That is what we will do in this problem. Create a temporary tabled called `temp_table` and save the dataframe into this table. Then run spark SQL to get the exact same result as Q2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3b85a-6900-4115-a14b-e1f8018253d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_10_sql = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f652c-66b6-4694-b157-56435ea59dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensure temp_table exists after completing your solution\n",
    "from pyspark.sql import SQLContext\n",
    "\"temp_table\" in SQLContext(spark).tableNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35a6a3-83c5-4c57-9a89-92b1e9aa2122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensure these run as well\n",
    "l2a = [('NJ', 39.3),\n",
    " ('LA', 38.6),\n",
    " ('MT', 37.1),\n",
    " ('WV', 37.1),\n",
    " ('CT', 36.7),\n",
    " ('IL', 36.6),\n",
    " ('DE', 36.3),\n",
    " ('AR', 36.3),\n",
    " ('TX', 36.1),\n",
    " ('AZ', 36.0)]\n",
    "for i, x in enumerate(first_10_sql):\n",
    "    assert l2a[i] == (x.locationabbr, x.max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76afbbbc-5551-4f5f-98cd-047b8b37b945",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Q2c (4 points)\n",
    "\n",
    "It would be interesting to know which `yearstart` value had the maximum value for each locationabbr. Write a query to find that. You can choose SQL or Spark dataframe to get the results. Again get the `max_value` in descending order and get the first 20 records\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e934833-bc5a-4e2e-8973-872b8a71ea0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_20_records = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f45c9b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b153dc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Upload this .zip file to Gradescope for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d3533",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11e119",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert result1['mother'] == 47\n>>> assert result1['other'] ==  2091\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert total_length == 12630\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> l2a = [('NJ', 39.3),\n...  ('LA', 38.6),\n...  ('MT', 37.1),\n...  ('WV', 37.1),\n...  ('CT', 36.7),\n...  ('IL', 36.6),\n...  ('DE', 36.3),\n...  ('AR', 36.3),\n...  ('TX', 36.1),\n...  ('AZ', 36.0)]\n>>> for i, x in enumerate(first_10_counts):\n...     assert l2a[i] == (x.locationabbr, x.max_value)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> l2c = [(39.3, '2013', 'NJ'),\n...  (38.6, '2013', 'LA'),\n...  (37.1, '2013', 'MT'),\n...  (37.1, '2013', 'WV'),\n...  (36.7, '2013', 'CT'),\n...  (36.6, '2013', 'IL'),\n...  (36.3, '2013', 'DE'),\n...  (36.3, '2013', 'AR'),\n...  (36.1, '2013', 'TX'),\n...  (36.0, '2013', 'AZ'),\n...  (35.6, '2013', 'MO'),\n...  (35.6, '2013', 'MA'),\n...  (35.3, '2013', 'ND'),\n...  (35.0, '2013', 'AL'),\n...  (34.8, '2013', 'FL'),\n...  (34.4, '2013', 'WY'),\n...  (34.0, '2013', 'NV'),\n...  (33.4, '2013', 'OK'),\n...  (33.0, '2017', 'VT'),\n...  (32.9, '2013', 'MS')]\n>>> \n>>> \n>>> for i, x in enumerate(first_20_records):\n...     assert l2c[i] == (x.max_value, x.yearstart, x.locationabbr)\n...     \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
