{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8b74a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"ps11.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1a19c7",
   "metadata": {},
   "source": [
    "# Problem Set 11\n",
    "## Logistic regression, automatic differentiation, and neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17142f",
   "metadata": {},
   "source": [
    "In this problem set you will study binary classification using logistic regression, and implement neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f3cca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8211663eb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "rng_seed = 507\n",
    "torch.manual_seed(rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c185eb1-917b-47a5-bfab-cc8fcd79019f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n, p = X.shape\n",
    "n, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc62c1d",
   "metadata": {},
   "source": [
    "## Question 1: Binary classification\n",
    "\n",
    "In this exercise you will use `sklearn` to build a binary classifier.\n",
    "\n",
    "Logistic regression assumes the probability model \n",
    "\n",
    "$$\\mathbb{P}(y_i=1\\mid \\mathbf{x}_i) = \\sigma(\\mathbf{x}_i^T\\boldsymbol{\\beta}),$$ \n",
    "\n",
    "where $\\mathbf{x}_i$ are rows of the data matrix $\\mathbf{X}\\in\\mathbb{R}^{n\\times p}$, $\\mathbf{y}\\in\\{0,1\\}^n$ is a vector of binary responses, and\n",
    "\n",
    "$$\\sigma(z)=\\frac{1}{1+\\exp(-z)}$$ \n",
    "\n",
    "is a *sigmoid* function which maps  real numbers into the interval $[0,1]$. \n",
    "\n",
    "In simple terms, a linear regression formula can be converted into a logistic regression by applying the sigmoid function. Using scikit-learn module, it gets very simple to apply these algorithms and that is what you will explore in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601676f4",
   "metadata": {},
   "source": [
    "The classifier will take as input a $28\\times 28$ grayscale MNIST image, and return `1` if the image represents the number 5, and `0` otherwise.\n",
    "\n",
    "*Note*: various algorithms implemented in `sklearn` are randomized. To utilize the same randomness as we did when generating the solutions (and hence, to ensure that your output passes the test cases), use `random_state=1` wherever necessary when calling `sklearn` methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f16323",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1(a)** (1 pt) Using the `mnist` data loaded above, create a standardized version of `X` where each column has zero mean and variance one. (Hint: use the `sklearn.preprocessing` module.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6354a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standard_scaler = sklearn.preprocessing.StandardScaler()\n",
    "Xs = standard_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb23a9bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>1a</pre></strong> passed! ✨</p>"
      ],
      "text/plain": [
       "1a results: All test cases passed!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2390fcca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1(b)** (1 pt) Using the `mnist` data loaded above, create a vector `y5` which equals `1` if the the corresponding MINST image equals is of the number 5, and `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd43a276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y5 = (y == 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb344c2e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>1b</pre></strong> passed! 🎉</p>"
      ],
      "text/plain": [
       "1b results: All test cases passed!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a53c6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1(c)**(1pt) Using `sklearn.model_selection.train_test_split`, divide the data into 70% training data and 30% test data. To ensure that your output matches our tests, pass the option `random_state=1` into the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71242b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(Xs, y5, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07ee9a67-949d-4753-8c84-ef89ba4d955d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y5==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd6b197",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>1c</pre></strong> passed! ✨</p>"
      ],
      "text/plain": [
       "1c results: All test cases passed!"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c91bb47",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1(d)**(2pt) Use `sklearn.linear_model.LogisticRegression` to train a binary classifier on the *training data only*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b30b1a35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2726fef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>1d</pre></strong> passed! 🙌</p>"
      ],
      "text/plain": [
       "1d results: All test cases passed!"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf91cae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**1(e)**(1pt) How accurate is your trained classifier on `X_train`/`y_train`?  Use confusion matrix. \n",
    "\n",
    "Refer: \n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "* https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "Assign values to variables called TP, FP, FN, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dd9f830-da11-4403-9c85-83956a99955c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28192456-f6c8-4d73-8ff9-8b9b4a4ced97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_test, y_test_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5641809e-a55b-4a64-8709-fe959356fedc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf797bad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>1e</pre></strong> passed! ✨</p>"
      ],
      "text/plain": [
       "1e results: All test cases passed!"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"1e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8081a1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**1(f)**(2pt) The regularization parameter can be varied by setting `LogisticRegression(C=C)` , where `C` is the value of the regularization penalty. What happens to the test error that you computed in the previous step as you vary `C`? Can you find a setting of `C` that results in lower test error than the default value `C=1`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8f05cb",
   "metadata": {},
   "source": [
    "In general, a smaller C specifies stronger regularization. This means the model becomes more generalized but might also be more underfit. On the contrary, a larger C results in less regularization, which allows the model to fit more to the training data but it might also overfit. \n",
    "\n",
    "A larger C will result in lower train error, but the test error might be higher or lower. Only if we train and compare different C can we know whether there is a setting of C that results in lower test error than default. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08c761",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292ade45",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2(a)**(2pt) In this problem you will understand how to calculate derivatives using pytorch. \n",
    "**Note:** If you do not use pytorch tensors to solve these problems, hidden tests will fail.\n",
    "\n",
    "Create a function called get_grad that receives a floating point value for 'x' and returns the gradient of the function at the given input value of 'x':\n",
    "\n",
    "$$y = x^2 + 3x + 5$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "475955e1-ace2-4582-be9f-23f0dbf733fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_grad(x):\n",
    "    return 2 * x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71ea6953",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>2a</pre></strong> passed! ✨</p>"
      ],
      "text/plain": [
       "2a results: All test cases passed!"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8df82b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2(b)**(2pt) \n",
    "We now extend the previous concept and get partial derivatives when you have two variables applied to the below function\n",
    "$$𝑓(𝑢,𝑣)=𝑣𝑢+𝑢^3$$\n",
    "\n",
    "Write a function 'get_grads' that takes in two floating point numbers corresponding to the two variables; u and v, and returns the gradients as a tuple with respect to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7433698-fd45-4f59-a047-4c57d6c1e38c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_grads(u, v):\n",
    "    return (v + 3 * u * u, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1101b3fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>2b</pre></strong> passed! 🌟</p>"
      ],
      "text/plain": [
       "2b results: All test cases passed!"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c064fc16",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2(c)**(2pt) Extend the linear regression model from scratch shown in class by adding the bias 'b'\n",
    "The linear function would be\n",
    "\n",
    "$$y = w * x + b$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8fc6ca0-18a2-4a6a-b45f-9915e799958f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = torch.arange(-3, 3, 0.1).view(-1, 1)\n",
    "f = 1 * X - 1\n",
    "Y = f + 0.1 * torch.randn(X.size())\n",
    "w = torch.tensor(-10.0, requires_grad = True)\n",
    "b = torch.tensor(10.0, requires_grad = True)\n",
    "lr = 0.1\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17289f1d-291e-4ab0-b04d-982c8564f6c8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def criterion(yhat, y):\n",
    "    return torch.mean((yhat - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96836799-595f-47dd-8d14-2bbe432de25b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    yhat = w * x + b\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "72fc7f2d-2c2b-40a2-b65f-80aad3dba90d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(epochs, X, Y, lr):\n",
    "    \n",
    "    optimizer = torch.optim.SGD([w, b], lr)\n",
    "    \n",
    "    for epoch in range (epochs):\n",
    "        Yhat = forward(X)\n",
    "        \n",
    "        # calculate the loss per iteration\n",
    "        loss = criterion(Yhat, Y)\n",
    "\n",
    "        # store the loss at every iteration\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        # backward pass: compute gradient \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3190dd2a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>2c</pre></strong> passed! 🌟</p>"
      ],
      "text/plain": [
       "2c results: All test cases passed!"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf3b3f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2(d)**(2pt)\n",
    "In this problem, you will learn to use the deep learning framework PyTorch\n",
    "We'll be using the Fashion MNIST dataset, which consists of 28x28 images that could be 10 different articles of clothing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d02cee4-5917-4274-9c63-aafad61977bf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:01<00:00, 15102004.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 266443.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:00<00:00, 5015793.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 9748206.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets as visiondata\n",
    "training_data = visiondata.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbe06f0-6a62-483b-91e7-baa7efd38ae0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run this cell to view a random sample from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6513c11e-a701-4226-98e0-76c7346d0ca2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce890b9-9d59-4339-8a94-5efd98c3e131",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Here are some helper functions used for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b46d794-762a-47bd-91f5-5d592949cf8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(model, transform_fn, loss_fn, optimizer, dataloader, num_epochs):\n",
    "    tbar = tqdm(range(num_epochs))\n",
    "    for _ in tbar:\n",
    "        loss_total = 0.\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            x = transform_fn(x)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y.squeeze(-1))\n",
    "            ## Parameter updates\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_total += loss.item()\n",
    "        tbar.set_description(f\"Train loss: {loss_total/len(dataloader)}\")\n",
    "        \n",
    "    return loss_total/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ec71d80b-0b42-4d93-8a90-8e9dd0932525",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_test_accuracy(model, transform_fn, test_dataloader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    tf = nn.Flatten()\n",
    "    for (xi, yi) in test_dataloader:\n",
    "        xi = transform_fn(xi)\n",
    "        pred = model(xi)\n",
    "        yi_pred = pred.argmax(-1)\n",
    "        y_true.append(yi)\n",
    "        y_pred.append(yi_pred)\n",
    "    y_true = torch.cat(y_true, dim = 0)\n",
    "    y_pred = torch.cat(y_pred, dim = 0)\n",
    "\n",
    "    accuracy = (y_true == y_pred).float().mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35044b3-7fe4-446f-b78b-07ef2c1dde78",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "NN consists of an input layer, an activation function, and another output layer. Write a class called MultiClassNN that subclasses nn.Module. This module contains one attribute, net, which is an nn.Sequential object that is called on the .forward(x) method. Your task is to write the __init__() method to correctly construct net.\n",
    "\n",
    "For example, if num_features=784, num_hidden=256, num_classes=10:\n",
    "\n",
    ">>> mlp = MultiClassNN(28**2, 256, 10)\n",
    ">>> mlp.net\n",
    "\n",
    "Sequential(\n",
    "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
    "  (1): Sigmoid()\n",
    "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
    "  (3): LogSoftmax(dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2544231a-cad3-4802-9fb4-88216c3303de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiClassNN(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, num_classes):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            num_features: The number of features in the input.\n",
    "            num_hidden: Number of hidden features in the hidden layer:\n",
    "            num_classes: Number of possible classes in the output\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(num_features, num_hidden, bias=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_hidden, num_classes, bias=True),\n",
    "            nn.LogSoftmax(dim = -1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "345ca832",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>2d</pre></strong> passed! 🚀</p>"
      ],
      "text/plain": [
       "2d results: All test cases passed!"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4978b23",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2(e)**(1pt) \n",
    "Construct a `DataLoader` object of the Fashion MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e331cc46-e6ed-4f88-8813-a5d0adcf5d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size = 128, shuffle = True, num_workers = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7dc7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**2(f)** \n",
    "(3pt) Initialize a `MultiClassNN` object called `mlp` and train it using the `train_loop()` function given at the beginning of the assignment (do not modify the `train_loop()` function). We will test your  `mlp` object on unseen test data.\n",
    "\n",
    "Hints:\n",
    "-  You need to initialize a `torch.optim.Optimizer` object for gradient descent. The standard choice is `torch.optim.Adam` with a learning rate `1e-3`.\n",
    "-  You need to flatten the Fashion MNIST dataset to use within the `MultiClassNN`. This should be done with the `transform_fn` argument to `train_loop`. Try `nn.Flatten()`.\n",
    "-  The output of `MultiClassNN` are the log probabilities of each class. To test the accuracy of your model, you should use the negative log-likelihood loss, `nn.NLLLoss()`, as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "82b8b4ab-2bcf-4441-9315-bea4443bb181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.21252329909661685: 100%|██████████| 20/20 [03:46<00:00, 11.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21252329909661685"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MultiClassNN(28**2, 256, 10)\n",
    "mlp_optimizer = torch.optim.Adam(mlp.parameters(), lr = 1e-3)\n",
    "loss_total = nn.NLLLoss()\n",
    "transform_fn = nn.Flatten()\n",
    "train_loop(mlp, transform_fn, loss_total, mlp_optimizer, train_dataloader, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42321e00",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe63543",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Upload this .zip file to Gradescope for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e651a6d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6295f",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "1a": {
     "name": "1a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> m = Xs.mean(axis = 0)\n>>> sd = Xs.std(axis = 0)\n>>> assert sum(abs(m)) < 1e-10\n>>> assert np.all(np.logical_or(abs(sd - 1) < 1e-10, abs(sd - 0) < 1e-10))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "1b": {
     "name": "1b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> place = np.where(y5 == 1)[0]\n>>> assert len(place) == 182\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "1c": {
     "name": "1c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X_train.shape[0] == 1257\n>>> assert y_train.shape[0] == 1257\n>>> assert X_test.shape[0] == 540\n>>> assert y_test.shape[0] == 540\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "1d": {
     "name": "1d",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sum(clf.predict(X_test)) == 47\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "1e": {
     "name": "1e",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert TP == 45\n>>> assert TN == 491\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2a": {
     "name": "2a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_grad(3.0) == 9.0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2b": {
     "name": "2b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_grads(1.0, 1.0) == (4.0, 1.0)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2c": {
     "name": "2c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> train_model(15, X, Y, 0.1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert w < 2\n>>> assert b < 1\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2d": {
     "name": "2d",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(MultiClassNN(2,2,2).net[0], torch.nn.modules.linear.Linear)\n>>> assert isinstance(MultiClassNN(2,2,2).net[1], torch.nn.modules.Sigmoid)\n>>> # HIDDEN\n>>> assert isinstance(MultiClassNN(2,2,2).net[2], torch.nn.modules.linear.Linear)\n>>> assert isinstance(MultiClassNN(2,2,2).net[3], torch.nn.modules.activation.LogSoftmax)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
